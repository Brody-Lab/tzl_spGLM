"""
	Characterization(model)

Compute quantities useful for characterizing the model

ARGUMENT
-a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

OPTIONAL ARGUMENT
-`nsamples`: number of samples to include within the composite

RETURN
-a composite containg quantities useful for understanding the model. See `types.jl` for details on each field of the composite.
"""

"""
	Characterization(testmodel, trainingmodel)
"""
function Characterization(model::Model)
	Characterization(LL = loglikelihood_each_timestep(model),
					 expectedemissions = ExpectedEmissions(model),

end


"""
	loglikelihood_each_trial(model)

Log(base-2)-likelihood of the emissions on each trial

ARGUMENT
-`model`: a struct containing the data, parameters, and hyperparameters

RETURN
-`â„“`: A nested array whose element `â„“[i][m]` is the log-likelihood of the m-th trial of i-th trialset
"""
function loglikelihood_each_trial(model::Model)
	log2e = log2(exp(1))
	memory = Memoryforgradient(model)
	concatenatedÎ¸ = concatenateparameters(model)
	P = update!(memory, model, concatenatedÎ¸)
	log_s = log(model.options.sf_y)
	â„“ = map(model.trialsets) do trialset
			N = length(trialset.mpGLMs)
			map(trialset.trials) do trial
				-N*trial.ntimesteps*log_s
			end
		end
	@inbounds for i in eachindex(model.trialsets)
		for m in eachindex(model.trialsets[i].trials)
			memory.â„“[1] = 0.0
			forward!(memory, P, model.Î¸native, model.trialsets[i].trials[m])
			â„“[i][m] += log2e*memory.â„“[1]
		end
	end
	return â„“
end

"""
	loglikelihood_choice_given_spikes(model)

Log(base 2)-likelihood of the choice on each trial, conditioned on the spike trains

ARGUMENT
-`model`:a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`â„“â‚‚ğ‘‘_ğ˜`: a nested array whose element â„“â‚‚ğ‘‘_ğ˜[i][m]` is the log(base 2)-likelihood of the choice in the m-th trial in the i-th trialset.
"""
function loglikelihood_choice_given_spikes(model::Model)
	memory = Memoryforgradient(model)
	P = update!(memory, model)
	memory_ğ˜ = Memoryforgradient(model)
	for i in eachindex(memory_ğ˜.pğ˜ğ‘‘)
		scaledlikelihood!(memory_ğ˜.pğ˜ğ‘‘[i], model.trialsets[i])
	end
	P_ğ˜ = update_for_latent_dynamics!(memory_ğ˜, model.options, model.Î¸native)
	log2e = log2(exp(1))
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			memory.â„“[1] = 0.0
			memory_ğ˜.â„“[1] = 0.0
			forward!(memory, P, model.Î¸native, trial)
			forward!(memory_ğ˜, P_ğ˜, model.Î¸native, trial)
			return log2e*(memory.â„“[1] - memory_ğ˜.â„“[1])
		end
	end
end

"""
	loglikelihood_choice_bernoulli(test_trialset, training_trialset)

Log-likelihood of the choices under a Bernoulli model

ARGUMENT
-`test_trialset`: held-out trials
-`training_trialset`: trials used to estimate the parameter of the Bernoulli distribution

RETURN
-`â„“â‚‚ğ‘‘_bernoulli`: nested array whose element `â„“â‚‚ğ‘‘_bernoulli[i][m]` is the log-likelihood of the choice in the m-th trial in the i-th trialset.
"""
function loglikelihood_choice_bernoulli(test_trialset::Trialset, training_trialset::Trialset)
	p = 0.0
	for trainingtrial in training_trialset.trials
		p+= trainingtrial.choice
	end
	p/=length(training_trialset.trials)
	logâ‚‚p = log2(p)
	logâ‚‚q = log2(1-p)
	map(test_trialset.trials) do testtrial
		testtrial.choice ? logâ‚‚p : logâ‚‚q
	end
end

"""
	loglikelihood_spiketrains_poisson(test_trialset, training_trialset)

Log-likelihood of the spike trains under a Bernoulli model

ARGUMENT
-`test_trialset`: held-out trials
-`training_trialset`: trials used to estimate the parameter of the Bernoulli distribution

RETURN
-`â„“â‚‚ğ²_poisson`: a nested array whose element `â„“â‚‚ğ²_poisson[m][n][t]` is the log-likelihood of observed spike count at the t-time step of the m-th trial for the n-th neuron.
"""
function loglikelihood_spiketrains_poisson(test_trialset::Trialset, training_trialset::Trialset)
	concatenatedâ„“s = map(test_trialset.mpGLMs, training_trialset.mpGLMs) do test_mpGLM, training_mpGLM
						Î»Î”t = mean(training_mpGLM.ğ²)
						map(y->log2(poissonlikelihood(Î»Î”t, y)), test_mpGLM.ğ²)
					end
	map(test_trialset.trials) do trial
		timesteps = trial.Ï„â‚€ .+ (1:trial.ntimesteps)
		map(concatenatedâ„“s) do concatenatedâ„“
			concatenatedâ„“[timesteps]
		end
	end
end

"""
	loglikelihood_spiketrains(model)

Log(base 2)-likelihood of the spike count of each neuron at each time step

ARGUMENT
-`model`:a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`â„“â‚‚ğ²`: a nested array whose element `â„“â‚‚ğ²[i][m][n][t]` is the log-likelihood of the spike count of n-th neuron of the i-th trialset on the t-th time step of the m-th trial within the i-th trialset.
"""
function loglikelihood_spiketrains(model::Model)
	memory = Memoryforgradient(model)
	P = update_for_âˆ‡latent_dynamics!(memory, model.options, model.Î¸native)
	pğ‘¦_ğšğœ = zeros(model.options.Î, model.options.K)
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			â„“â‚‚ğ² = collect(zeros(trial.ntimesteps) for mpGLM in trialset.mpGLMs)
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			pğš = memory.pğšâ‚
			pğœ = memory.Ï€á¶œ
			for t=1:trial.ntimesteps
				if t > 1
					Aáµƒ = transitionmatrix(trial.clicks, memory.Aáµƒinput, memory.Aáµƒsilent, t)
					pğš = Aáµƒ*pğš
					pğœ = memory.Aá¶œ*pğœ
				end
				Ï„ = trial.Ï„â‚€ + t
				for (mpGLM, â„“â‚‚ğ²) in zip(trialset.mpGLMs, â„“â‚‚ğ²)
					conditionallikelihood!(pğ‘¦_ğšğœ, mpGLM, Ï„)
					â„“â‚‚ğ²[t] = log2(pğš'*pğ‘¦_ğšğœ*pğœ)
				end
			end
			return â„“â‚‚ğ²
		end
	end
end

"""
	ExpectedEmissions(model, nsamples)

Compute the expectation of the choice and spike train on each trial by averaging across simulations

While the expectation of the choice can be computed without simulation, the expectation of a spike train requires simulation due to the spike history input.

Note the similarity between this function and `drawsamples`

ARGUMENT
-`model`: a composite containing the data, parameters, and hyperparameters of the factorial hidden-Markov drift-diffusion model
-`nsamples`: number of samples to draw

RETURN
-`expectedemissions`: a nested array whose element `expectedemissions[i][m]` contains the expected choice and the choice-conditioned spike trains of each neuron on the m-th trial of the i-th trialset.
"""
function ExpectedEmissions(model::Model, nsamples)
	memory = Memoryforgradient(model)
	P = update_for_latent_dynamics!(memory, model.options, model.Î¸native)
	a = zeros(Int, memory.maxtimesteps)
	c = zeros(Int, memory.maxtimesteps)
	ğ› = model.trialsets[1].mpGLMs[1].dğ›_dB.*model.Î¸native.B[1]
	map(model.trialsets) do trialset
		ğ„ğ = map(mpGLM->externalinput(mpGLM), trialset.mpGLMs)
		ğ¡ = map(mpGLM->postspikefilter(mpGLM), trialset.mpGLMs)
		ğ›š = map(mpGLM->transformaccumulator(mpGLM), trialset.mpGLMs)
		map(trialset.trials) do trial
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			Eğ˜left = collect(zeros(trial.ntimesteps) for mpGLM in trialset.mpGLMs)
			Eğ˜right = deepcopy(Eğ˜left)
			nright = 0
			for s = 1:nsamples
				trialsample = sampletrial!(a, c, ğ„ğ, ğ¡, memory, ğ›š, model.Î¸native.Ïˆ[1], trial, trialset, ğ›)
				nright += trialsample.choice
				Eğ˜ = trialsample.choice ? Eğ˜right : Eğ˜left
				for (Eğ², ğ²) in zip(Eğ˜, trialsample.spiketrains)
					for t in eachindex(Eğ²)
						Eğ²[t] += ğ²[t]
					end
				end
			end
			nleft = nsamples-nright
			if nleft > 0
				for Eğ²left in Eğ˜left
					for t in eachindex(Eğ²left)
						Eğ²left[t] /= nleft
					end
				end
			end
			if nright > 0
				for Eğ²right in Eğ˜right
					for t in eachindex(Eğ²right)
						Eğ²right[t] /= nright
					end
				end
			end
			ExpectedEmissions(rightchoice=nright/nsamples,
							spiketrain_leftchoice=Eğ˜left,
							spiketrain_rightchoice=Eğ˜right)
		end
	end
end

"""
	Characterization(cvindices, testmodels, trainingmodels)

Out-of-sample computation of quantities for characterizing the model

ARGUMENT
-`cvindices`: a vector of composites, each of which containing the indices of trials used for testing and training for a particular cross-validation fold
-`testmodels`: a vector of composites, each of which containing the held-out data for a cross-validation fold
-`trainingmodels`: a vector of composites, each of which containing the training data for a cross-validation fold
"""
function Characterization(cvindices::Vector{<:CVIndices}, testmodels::Vector{<:Model}, trainingmodels::Vector{<:Model}; nsamples::Integer=100)
	characterization_each_fold = map((testmodel, trainingmodel)->Characterization(testmodel, trainingmodel; nsamples=nsamples), testmodels, trainingmodels)
	ntrialsets = length(cvindices[1].testingtrials)
	trialindices = collect(sortperm(vcat((cvindex.testingtrials[i] for cvindex in cvindices)...)) for i=1:ntrialsets)
	values =
		map(fieldnames(Characterization)) do fieldname
			map(1:ntrialsets) do i
				field = vcat((getfield(characterization, fieldname)[i] for characterization in characterization_each_fold)...)
				field[trialindices[i]]
			end
		end
	Characterization(values...)
end

"""
	save(characterization, folderpath)

Save the characterizations of the model.

Each field of the composite `characterization` is saved within a separate file, with the same name as that of the field, within a folder whose absolute path is specified by `folderpath`.
"""
function save(characterization::Characterization, folderpath::String)
	if !isdir(folderpath)
		mkdir(folderpath)
		@assert isdir(folderpath)
	end
	for fieldname in fieldnames(Characterization)
		filepath = joinpath(folderpath, String(fieldname)*".mat")
		if fieldname==:expectedemissions
			entry =
				map(characterization.expectedemissions) do expectedemissions
					map(expectedemissions) do expectedemissions
						dictionary(expectedemissions)
					end
				end
		else
			entry = getfield(characterization, fieldname)
		end
		dict = Dict(String(fieldname)=>entry)
	    matwrite(filepath, dict)
	end
end
